\documentclass[12pt,A4]{extarticle}	
\usepackage{filecontents}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amssymb}

\begin{filecontents*}{\jobname.bib}
  @article{DistributedSystemVanSteenTanenbaum,
  author       = {Maarten van Steen and
                  Andrew S. Tanenbaum},
  title        = {A brief introduction to distributed systems},
  journal      = {Computing},
  volume       = {98},
  number       = {10},
  pages        = {967--1009},
  year         = {2016},
  url          = {https://doi.org/10.1007/s00607-016-0508-7},
  doi          = {10.1007/s00607-016-0508-7},
  timestamp    = {Thu, 14 Oct 2021 09:12:09 +0200},
  biburl       = {https://dblp.org/rec/journals/computing/SteenT16.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@article{lamportTimeClocks,
author = {Lamport, Leslie},
title = {Time, clocks, and the ordering of events in a distributed system},
year = {1978},
issue_date = {July 1978},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {21},
number = {7},
issn = {0001-0782},
url = {https://doi.org/10.1145/359545.359563},
doi = {10.1145/359545.359563},
abstract = {The concept of one event happening before another in a distributed system is examined, and is shown to define a partial ordering of the events. A distributed algorithm is given for synchronizing a system of logical clocks which can be used to totally order the events. The use of the total ordering is illustrated with a method for solving synchronization problems. The algorithm is then specialized for synchronizing physical clocks, and a bound is derived on how far out of synchrony the clocks can become.},
journal = {Commun. ACM},
month = {jul},
pages = {558–565},
numpages = {8},
keywords = {clock synchronization, computer networks, distributed systems, multiprocess systems}
}
@article{BRACHA1987130,
title = {Asynchronous Byzantine agreement protocols},
journal = {Information and Computation},
volume = {75},
number = {2},
pages = {130-143},
year = {1987},
issn = {0890-5401},
doi = {https://doi.org/10.1016/0890-5401(87)90054-X},
url = {https://www.sciencedirect.com/science/article/pii/089054018790054X},
author = {Gabriel Bracha},
abstract = {A consensus protocol enables a system of n asynchronous processes, some of them faulty, to reach agreement. Both the processes and the message system are capable of cooperating to prevent the correct processes from reaching decision. A protocol is t-resilient if in the presence of up to t faulty processes it reaches agreement with probability 1. Byzantine processes are faulty processes that can deviate arbitrarily from the protocol; Fail-Stop processes can just stop participating in it. In a recent paper, t-resilient randomized consensus protocols were presented for t<n5. We improve this to t < n3, thus matching the known lower bound on the number of correct processes necessary for consensus. The protocol uses a general technique in which the behavior of the Byzantine processes is restricted by the use of a broadcast protocol that filters some of the messages. The apparent behavior of the Byzantine processes, filtered by the broadcast protocol, is similar to that of Fail-Stop processes. Plugging the broadcast protocol as a communicating primitive into an agreement protocol for Fail-Stop processes gives the result. This technique, of using broadcast protocols to reduce the power of the faulty processes and then using them as communication primitives in algorithms designed for weaker failure models, was used succesfully in other contexts.}
}
@article{impossibilityDistributedConsensus,
author = {Fischer, Michael J. and Lynch, Nancy A. and Paterson, Michael S.},
title = {Impossibility of distributed consensus with one faulty process},
year = {1985},
issue_date = {April 1985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {32},
number = {2},
issn = {0004-5411},
url = {https://doi.org/10.1145/3149.214121},
doi = {10.1145/3149.214121},
abstract = {The consensus problem involves an asynchronous system of processes, some of which may be unreliable. The problem is for the reliable processes to agree on a binary value. In this paper, it is shown that every protocol for this problem has the possibility of nontermination, even with only one faulty process. By way of contrast, solutions are known for the synchronous case, the “Byzantine Generals” problem.},
journal = {J. ACM},
month = {apr},
pages = {374–382},
numpages = {9}
}
@inproceedings {PBFT,
author = {Miguel Castro and Barbara Liskov},
title = {Practical Byzantine Fault Tolerance},
booktitle = {3rd Symposium on Operating Systems Design and Implementation (OSDI 99)},
year = {1999},
address = {New Orleans, LA},
url = {https://www.usenix.org/conference/osdi-99/practical-byzantine-fault-tolerance},
publisher = {USENIX Association},
month = feb
}
@inproceedings{dagRider,
author = {Keidar, Idit and Kokoris-Kogias, Eleftherios and Naor, Oded and Spiegelman, Alexander},
title = {All You Need is DAG},
year = {2021},
isbn = {9781450385480},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3465084.3467905},
doi = {10.1145/3465084.3467905},
abstract = {We present DAG-Rider, the first asynchronous Byzantine Atomic Broadcast protocol that achieves optimal resilience, optimal amortized communication complexity, and optimal time complexity. DAG-Rider is post-quantum safe and ensures that all values proposed by correct processes eventually get delivered. We construct DAG-Rider in two layers: In the first layer, processes reliably broadcast their proposals and build a structured Directed Acyclic Graph (DAG) of the communication among them. In the second layer, processes locally observe their DAGs and totally order all proposals with no extra communication.},
booktitle = {Proceedings of the 2021 ACM Symposium on Principles of Distributed Computing},
pages = {165–175},
numpages = {11},
keywords = {asynchrony, atomic broadcast, byzantine smr, quantum safe},
location = {Virtual Event, Italy},
series = {PODC'21}
}
\end{filecontents*}

\newcommand{\lectureTitle}{Decentralized Systems [WIP]}
\newcommand{\lectureSubtitle}{Fundamentals, Modeling, and Applications}
\newcommand{\semester}{Sommersemester 2024}

\newcommand{\titleSize}{\LARGE}

\input{../shared/summary-boilerplate.tex}
\cfoot{\thepage\ $/$ \pageref*{LastPage}}


\definecolor{highlightColor}{RGB}{66, 135, 245}
\newcommand{\highlight}[1]{\textcolor{highlightColor}{\textbf{#1}}}

\def\contentsname{\empty}

\begin{document}

\disclaimer

\tableofcontents
\clearpage

\section{Introduction}
\subsection{What is a distributed system?}
\subsubsection{Characteristics by van Steen and Tanenbaum}
``\textit{A distributed system is a collection of autonomous computing elements that appears to its users as a single coherent system.}'' (\cite{DistributedSystemVanSteenTanenbaum}), this results in two characteristics:
\begin{enumerate}
  \item{``\textbf{Collection of autonomous computing elements}'': ``\textit{In practice, nodes are programmed to achieve common goals, which are realized by exchanging messages with each other}'' \\(\cite{DistributedSystemVanSteenTanenbaum})}
  \item{``\textbf{Appears as a single coherent system}'': Appears as a single large system}
\end{enumerate}

\subsubsection{Aspects of characteristic 1}
\begin{itemize}
  \item{``\textit{we cannot assume that there is something like a global clock}'' (\cite{DistributedSystemVanSteenTanenbaum}), therefore the \textbf{synchronization and coordination} between participants must be worked out}
  \item{``\textit{The fact that we are dealing with a collection of nodes implies that we may also need to manage the membership and organization of that collection}'' (\cite{DistributedSystemVanSteenTanenbaum}), therefore we need to think about identities and possible access-restrictions}
\end{itemize}

\subsubsection{Aspects of characteristic 2}
\begin{itemize}
  \item{``\textit{To assist the development of distributed applications, distributed systems are often organized to have a separate layer of software that is logically placed on top of the respective operating systems of the computers that are part of the system [...] leading to what is known as middleware}'' (\cite{DistributedSystemVanSteenTanenbaum})}
\end{itemize}

\subsubsection{Observations}
\begin{itemize}
  \item{Distributing tasks and aggregating a result from them is not easy at all}
  \item{The coordination of those tasks is still \textbf{centralized}}
\end{itemize}

\subsection{What makes a distributed system a decentralized system?}
According to \textbf{ISO/TC 307}: ``\textit{distributed system wherein control is distributed among the persons or organizations participating in the operation of the system}''

\subsubsection{Three types of Decentralization (Vitalik Buterin)}
\href{https://medium.com/@VitalikButerin/the-meaning-of-decentralization-a0c92b76a274}{Vitalik Buterin defines three types of Decentralization}:
\begin{itemize}
  \item{\textbf{Architectural (de)centralization}: How many \textbf{physical computers} is a system made up of? How many of those computers can it tolerate breaking down at any single time?}
  \item{\textbf{Political (de)centralization}: How many \textbf{individuals or organizations} ultimately control the computers that the system is made up of?}
  \item{\textbf{Logical (de)centralization}: Does the \textbf{interface and data structures} that the system presents and maintains look more like a single monolithic object, or an amorphous swarm? One simple heuristic is: if you cut the system in half, including both providers and users, will both halves continue to fully operate as independent units?}
\end{itemize}

\subsubsection{Our definition of decentralized systems}
\begin{itemize}
  \item{A decentralized system has political decentralization, where multiples parties are making their own independent decisions (they can still coordinate with each other)}
  \item{If a system is architecturally but not politically decentralized, we call it a distributed system}
  \item{Decentralized systems can be \textbf{logically decentralized or centralized}}
  \item{Decentralized systems can be open systems (anybody can participate) or closed systems}
\end{itemize}

\subsection{Reasons for decentralization}
\subsubsection{Reasons for architectural decentralization}
\begin{itemize}
  \item{\textbf{Latency}}
  \item{\textbf{Scalability}: Scale number of machines running the system}
  \item{Increase \textbf{fault tolerance} and \textbf{availability}, remove single point of failures}
  \item{Increase \textbf{attack resistance}, because no central points exist}
\end{itemize}

\subsubsection{Reasons for political decentralization}
\begin{itemize}
  \item{\textbf{Collusion resistance}: It is harder for participants to collude in ways that benefit a small group at the expense of other participants}
  \item{\textbf{Power} can be distributed ``equally''}
\end{itemize}

\subsubsection{Reasons for logical decentralization}
Logical decentralization is not always possible or even wanted, especially in use cases we cover. Example: \textbf{Distributed Ledgers}, where the goal is to have one commonly agreed system state at any point in time.

\subsection{Challenges of decentralization}
Decentralized systems come with risks/challenges to avoid harm to the system or its participants:
\begin{itemize}
  \item{\textbf{Time and synchrony}: Do we have a global clock? Is the communication synchronous or asynchronous?}
  \item{\textbf{behavior} of nodes: Can we handle arbitrary behavior? How many faulty nodes can we tolerate?}
  \item{\textbf{Identity}: Do we have an open system? Are nodes (identities) known?}
\end{itemize}

\section{Fundamentals}
\subsection{How to model a distributed system?}
We define a \textbf{distributed system} as a set of identical processes (or processors) that execute a program. Coordination between the processors is needed. The combination of processes form an application.

\subsubsection{Processes (Processors) and Messages}
A distributed system or algorithm consists of $n$ \highlight{processors} (called nodes/agents/participants) $p_0, \dots, p_{n-1}$.\par
Each process runs a local process and the processors cooperate on some \underline{common} task. They can communicate with each other.\par
\highlight{Messages} are uniquely identified by the sender using a sequence number of a logical clock.

\subsubsection{Links}
A \highlight{link} (channel) $\{p_i, p_j\}$ connects processors $i$ and $j$. Links are always considered \textbf{bidirectional}.\par
The network is a collection of all channels, the tolopogy is a pattern of channels (e.g. mesh, star).

\subsubsection{Inter-Process Communication}
Processors are communicating by \textbf{passing messages} to \textbf{in-} and \textbf{outboxes}. The address is a set of processes. Processors have access to \highlight{shared memory}.

\subsubsection{Automata and Steps}
We can model a distributed algorithm as a distributed collection of \highlight{automata} (one per process). Each automata is a state machine with defined states (\textbf{configurations}) and state transitions (\textbf{step}) that are triggered by an \textbf{event}.

\subsubsection{Safety and Liveness}
\begin{itemize}
  \item{\highlight{Safety}: ``\textit{Nothing bad has happened, yet}'': If a safety property is violated, we can point to a specific point in time where the violation occurred, \textbf{the violation cannot be undone}.}
  \item{\highlight{Liveness}: ``\textit{Eventually something good happend}'': At any time, there is the chance that the property will be satisfied at a later point in time.}
\end{itemize}

\subsection{Assumptions}
\subsubsection{Why do distributed algorithms need assumptions?}
Distributed algorithms deal with a lot of uncertainty, therefore we need assumptions to describe the \textbf{uncertainty} and \textbf{guarantees} of the system. Typical are
\begin{itemize}
  \item{\textbf{Process assumptions}: Crash behavior, adherance to the protocol}
  \item{\textbf{Communication assumptions}: Topology, reliability, attackers}
  \item{\textbf{Timing assumptions}: Latency, synchrony}
  \item{\textbf{Cryptographic assumptions}: Cryptographic primitives (e.g. encryption, signatures)}
  \item{\textbf{Setup assumptions}: What information is available to the participants at the start}
\end{itemize}

\subsubsection{Uniform/Nonuniform}
\begin{itemize}
  \item{\textbf{Uniform}: Total number of processors $n$ is not known to the algorithm}
  \item{\textbf{Nonuniform}: Each processor knows the total number of processors $n$}
\end{itemize}

\subsubsection{Fault model}\label{sec:faultModel}
The \highlight{Fault model} abstracts faults in the processors and channels.
\begin{itemize}
  \item{\highlight{Crash fault}: Processor works correctly until it crashes and never recovers}
  \item{\highlight{Omission fault}: Processor fails to send/receive messages it is supposed to send/receive (e.g. due to buffer overflow)}
  \item{\highlight{Crashes with recoveries}: Either the process crashes and never recovers or the process keeps crashing and recovering infinitely often}
  \item{\highlight{Byzantine fault}: Arbitrary behavior, the process can deviate from the protocol in any way}
\end{itemize}

\subsubsection{Fault tolerance}
The \highlight{Fault tolerance} of a system is the number of faulty processes $f$ out of $n$ processes that the system can tolerate while still operating correctly.

\subsubsection{Communication: Fair-loss links}
\textbf{Fair-loss links} are defined by three properties:
\begin{enumerate}
  \item{\textit{Fair-loss}: If a correct process $p$ infinitely often sends a message $m$ to a correct process $q$, then $q$ delivers $m$ an infinite number of times}
  \item{\textit{Finite duplication}: If a correct process $p$ sends a message $m$ a finite number of times to a process $q$, then $m$ cannot be delivered an infinite number of times by $q$}
  \item{\textit{No creation}: If some process $q$ delivers a message $m$ with sender $p$, then $m$ was previously sent to $q$ by $p$}
\end{enumerate}

\subsubsection{Communication: Perfect links}\label{sec:perfectLinks}
\textbf{Perfect links} are also defined by three properties:
\begin{enumerate}
  \item{\textit{Reliable delivery}: If a correct process $p$ sends a message $m$ to a correct process $q$, then $q$ eventually delivers $m$}
  \item{\textit{No duplication}: No message is delivered by a process more than once}
  \item{\textit{No creation}: If some process $q$ delivers a message $m$ with sender $p$, then $m$ was previously sent to $q$ by $p$}
\end{enumerate}
\textbf{Authenticated perfect links} are an extension of perfect links.

\subsubsection{Timing Models}
The \highlight{Timing model} describes the timing assumptions of the communication and execution behavior:
\begin{itemize}
  \item{\highlight{Synchronous model}: There is a \textbf{known upper bound} on processing delays and on message transmission delays}
  \item{\highlight{Asynchronous model}: There is \textbf{no timing assumption at all}. The execution and message delivery happens at an arbitrary speed, \textbf{but messages arrive eventually}}
\end{itemize}

\subsection{Time in Asynchronous Systems}
\subsubsection{Logical clocks: Lamport Clocks}
\highlight{Lamport clocks} are used to \textbf{measure passage of time} in \textbf{asynchronous systems}.
\begin{itemize}
  \item{Each process $p_i$ has a \textbf{logical clock} $l_i$, initially set to $0$}
  \item{Upon an event (sending or receiving a message), $l_i$ is incremented by $1$}
  \item{When sending a message $m$, process $p_i$ adds a timestamp $t_m = l_i$ to the message}
  \item{When receiving a message $m$, process $p_j$ increases its timestamp to $\max(l_j, t_m) + 1$}
\end{itemize}
With this, a \textbf{happened-before relationship} between events is established. For any two events $e_1, e_2$: $e_1 \rightarrow e_2 \Rightarrow t(e_1) < t(e_2)$.\par
This defines a \textbf{partial order} on the events.

\subsubsection{Hybrid: Partial Synchrony}
A hybrid between synchrony and asynchrony is \textbf{partial synchrony}, which comes in two variants:
\begin{itemize}
  \item{\textbf{Eventually synchronous}/Global Stabilization Time (GST): An event GST occurs after some finite time, afterwards time bound $\Lambda$ holds}
  \item{\textbf{Unknown Latency (UL)}: The system is always synchronous, but the delay bound $\Lambda$ is unknown}
\end{itemize}
Algorithms for these models typically increment their estimation of the delay bound dynamically.

\subsection{Combining Abstractions for Assumptions}
\subsubsection{Fail-stop}
\begin{itemize}
  \item{\hyperref[sec:faultModel]{Crash faults}}
  \item{\hyperref[sec:perfectLinks]{Perfect links}}
  \item{Perfect failure detector}
\end{itemize}

\subsubsection{Fail-silent}
\begin{itemize}
  \item{\hyperref[sec:faultModel]{Crash faults}}
  \item{\hyperref[sec:perfectLinks]{Perfect links}}
  \item{No failure detector}
\end{itemize}

\subsubsection{Fail-arbitrary}
\begin{itemize}
  \item{\hyperref[sec:faultModel]{Byzantine faults}}
  \item{\hyperref[sec:perfectLinks]{Authenticated perfect links}}
\end{itemize}

\subsection{Problem Statement: Leader Election}
\subsubsection{Problem definition}
\begin{itemize}
  \item{Group of processors has to elect one of them as leader}
  \item{Exactly one processor enters an elected state, all others enter a non-elected state}
\end{itemize}

\subsubsection{Anonymous rings}
\begin{itemize}
  \item{Processors have no identifiers}
  \item{Each processor has the same deterministic state machine}
  \item{Each processor is connected to two other processors}
\end{itemize}

\subsubsection{Leader Election in Anonymous Rings}
``\textit{There is no nonuniform anonymous algorithm for leader election in synchronous rings.}''\par
So, even with these strong assumptions, \textbf{leader election is not possible with anonymous participants}.

\subsubsection{Leader Election in Asynchronous Rings}
Setup assumptions:
\begin{itemize}
  \item{Assign each processor $p_i$ a unique identifier $id_i$}
  \item{Label the two connected processors of $p_i$ as \textit{left} and \textit{right neighbor}}
\end{itemize}

\begin{algorithm}
  \caption{Algorithm for Leader Election in Asynchronous Rings}
  \begin{algorithmic}
    \State \textbf{Each processor sends its identifier to its left neighbour.}
    \State \textbf{When a processor receives a termination message, it forwards it to the left neighbour and terminates as non-leader.}\\
    \State \textbf{Upon receiving message $m$ from right neighbour}
    \State \hspace{\algorithmicindent} \textbf{if $m < id_i$ then}
    \State  \hspace{\algorithmicindent}\hspace{\algorithmicindent} \textbf{drop message}
    \State \hspace{\algorithmicindent} \textbf{else if $m > id_i$ then}
    \State  \hspace{\algorithmicindent}\hspace{\algorithmicindent} \textbf{forward $m$ to left neighbour}
    \State \hspace{\algorithmicindent} \textbf{else if $m == id_i$ then}
    \State  \hspace{\algorithmicindent}\hspace{\algorithmicindent} \textbf{Send termination message to left neighbour}
    \State  \hspace{\algorithmicindent}\hspace{\algorithmicindent} \textbf{Terminate as leader}
    \State \hspace{\algorithmicindent} \textbf{end if}
  \end{algorithmic}
\end{algorithm}

The algorithm sends not more than $O(n^2)$ messages. Nonuniforms algorithms for synchronous rings also exist.

\subsection{Problem Statement: Mutual Exclusion}
\subsubsection{Problem definition}
\textbf{Mutual exclusion} is a known problem from concurrent computing. We need to ensure than critical sections are only accessible by one processor at a time. The desired sequence is Entry $\Rightarrow$ Critical section $\Rightarrow$ Exit.\par
The following three objectives should be satisfied:
\begin{itemize}
  \item{\textbf{Mutual exclusion}: At most one process can be in the critical section at any time (\textbf{Safety})}
  \item{\textbf{No Deadlock}: If some processor enters an entry section, some processor will later enter a critical section.}
  \item{\textbf{No lockout (starvation)}: If some processor enters an entry section, \textbf{that same processor} will later enter a critical section.}
\end{itemize}

\subsubsection{Lamport Mutual Exclusion}
Lamport defined a mutual exclusion algorithm based on \textbf{logical clocks} \cite{lamportTimeClocks}, the algorithm is not covered in this summary.

\subsection{Formalization via Modules}
We can now combine abstractions using \highlight{Modules}. A module has a \textbf{name}, \textbf{events} and \textbf{safety \& liveness properties}.\par
An algorithm \textit{implements} a module (and can build on other modules).

\newpage
\subsubsection{Module: Perfect Failure Detector}
\textbf{Events}:
\begin{itemize}
  \item{\textbf{Indication}: $\langle \mathcal{P}, \textit{Crash} \mid p \rangle$: Detects that process $p$ has crashed}
\end{itemize}
\textbf{Properties}:
\begin{itemize}
  \item{\textbf{PFD1:} \textit{Strong completeness}: Eventually, every process that crashes is permanently detected by every correct process}
  \item{\textbf{PFD2:} \textit{Strong accuracy}: If a process $p$ is detected by any process, then $p$ has crashed}
\end{itemize}
Perfect Failure Detector is implemented by ``Exclude on Timeout'' (not covered in this summary).

\subsubsection{Module: Eventually Perfect Failure Detector}
\textbf{Events}:
\begin{itemize}
  \item{\textbf{Indication}: $\langle \diamond \mathcal{P}, \textit{Suspect} \mid p \rangle$: Notifies that process $p$ is suspected to have crashed}
  \item {\textbf{Indication}: $\langle \diamond \mathcal{P}, \textit{Restore} \mid p \rangle$: Notifies that process $p$ is not suspected anymore}
\end{itemize}

\textbf{Properties}:
\begin{itemize}
  \item{\textbf{EPFD1:} \textit{Strong completeness}: Eventually, every process that crashes is permanently suspected by every correct process}
  \item{\textbf{EPFD2:} \textit{Eventual strong accuracy}: Eventually, no correct process is suspected by any correct process}
\end{itemize}
Eventually Perfect Failure Detector is implemented by ``Increasing Timeout'' (not covered in this summary).

\subsubsection{Module: Leader Election}
\textbf{Events}:
\begin{itemize}
  \item{\textbf{Indication}: $\langle le, \textit{Leader} \mid p \rangle$: Indicates that process $p$ is elected as leader}
\end{itemize}

\textbf{Properties}:
\begin{itemize}
  \item{\textbf{LE1:} \textit{Eventual detection}: Either there is no correct process, or some correct process is eventually elected as the leader}
  \item{\textbf{LE2:} \textit{Accuracy}: If a process is leader, then all previously elected leaders have crashed}
\end{itemize}
Leader Election is implemented by ``Monarchical Leader Election'' (not covered in this summary).

\subsubsection{Module: Eventual Leader Detector}
\textbf{Events}:
\begin{itemize}
  \item{\textbf{Indication}: $\langle \Omega, \textit{Trust} \mid p \rangle$: Indicates that process $p$ is trusted to be leader}
\end{itemize}

\textbf{Properties}:
\begin{itemize}
  \item{\textbf{ELD1:} \textit{Eventual accuracy}: There is a time after which every correct process trusts some correct process}
  \item{\textbf{ELD2:} \textit{Eventual agreement}: There is a time after which no two correct processes trust different processes}
\end{itemize}
Eventual Leader Detector is implemented by ``Monarchical Eventual Leader Detection'' (not covered in this summary).

\subsection{Quorums}
A \highlight{Quorum} is a set of processes with special properties. They are used for fault-tolerant algorithms. Dealing with $N$ crash-fault processes, \textbf{a quorum is any majority of processes}.\par
Assumption: There is a quorum of non-faulty processes (number of faulty processes $f < N/2$).\par
\textbf{Properties}:
\begin{itemize}
  \item{Two quorums intersect in at least one process}
  \item{In every quorum is at least one correct (non-faulty) process}
\end{itemize}
Dealing with $N$ arbitrary-fault processes (byzantine): To maintaing the second property, a quorum needs to be a set of more than $\frac{N+f}{2}$ processes. We call a set of more than $\frac{N+f}{2}$ a \highlight{byzantine quorum}.\par
When the required property is that there exists a Byzantine quorum of correct processes, $3f < N$ needs to hold.

\section{Reliable Broadcast}
Reliable broadcast is used to \textbf{share information} among processors withous losses, duplicates, etc.
\subsection{Module: Best Effort Broadcast}
\textbf{Events}:
\begin{itemize}
  \item{\textbf{Request}: $\langle beb, \textit{Broadcast} \mid m \rangle$: Broadcast a message $m$ to all processes}
  \item{\textbf{Indication}: $\langle beb, \textit{Deliver} \mid p, m \rangle$: Deliver a message $m$ broadcast by process $p$}
\end{itemize}

\textbf{Properties}:
\begin{itemize}
  \item{\textbf{Liveness:}
              \begin{itemize}
                \item{\textit{Validity}: If a correct process $p$ broadcasts $m$, then every correct process eventually delivers $m$}
              \end{itemize}
        }
  \item{\textbf{Safety:}
              \begin{itemize}
                \item{\textit{No duplication}: No message is delivered more than once}
                \item{\textit{No creation}: If a process delivers a message $m$ with sender $s$, then $m$ was prev. broadcast by $s$}
              \end{itemize}}
\end{itemize}
Best Effort Broadcast is implemented by ``Best Effort Broadcast Algorithm'' (not covered in this summary).

\subsection{Module: Reliable Broadcast}
\textbf{Events}:
\begin{itemize}
  \item{\textbf{Request}: $\langle rb, \textit{Broadcast} \mid m \rangle$: Broadcast a message $m$ to all processors}
  \item{\textbf{Indication}: $\langle rb, \textit{Deliver} \mid p, m \rangle$: Deliver a message $m$ broadcast by processor $p$}
\end{itemize}

\textbf{Properties}:
\begin{itemize}
  \item{\textbf{Validity}: If a correct processor $p$ broadcasts $m$, then $p$ eventually delivers $m$}
  \item{\textbf{No duplication}: No message is delivered more than once}
  \item{\textbf{No creation}: If a processor delivers $m$ from sender $s$, then $m$ was previously broadcast by $s$}
  \item{\textbf{Agreement}: If a message $m$ is delivered by some correct processor, then $m$ is eventually delivered by every correct processor}
\end{itemize}
Reliable Broadcast is implemented by ``Reliable Broadcast Algorithm'' (not covered in this summary).

\subsection{Byzantine Reliable Broadcast: Synchronous Case}
\textbf{Problem}: Components in a distributed system don't always fail ``orderly'' (crash-fault), but they can fail in arbitrary and potentially malicious ways. Therefore we need to focus on \highlight{Byzantine failures}.

\subsubsection{Interactive Consistency}
There are $i = 1, \dots, n$ independent processors, at most $f$ of which exhibit \textbf{arbitrary faults}. Non-faulty processors have a private value $v_i$.\par
\textbf{Assumptions}:
\begin{itemize}
  \item{\textbf{A1: Reliability}: Sent messages are delivered correctly}
  \item{\textbf{A2: Authenticity}: The receiver of a message knows the sender}
  \item{\textbf{A3: Synchrony}: Absence of a message is detectable}
\end{itemize}
The goal is \highlight{Interactive Consistency}: Processors compute a vector such that
\begin{itemize}
  \item{Non-faulty processors compute a $n$-dimensional vector}
  \item{Non-faulty processors compute exactly the same vector}
  \item{The values corresponding to non-faulty processors are their private value}
  \item{The values of faulty processors can be arbitrary, but must be consistent}
\end{itemize}

\subsubsection{Challenges}
Faulty processors can lie about themselves and others:
\begin{itemize}
  \item{\highlight{Equivocation}: A processor sends different/contradicting information to different processors}
  \item{\highlight{Relay Forgery}: A processor passes on different information than received}
\end{itemize}

\subsubsection{Impossibility Result}
It can be shown that $3f$ processors are insufficient to overcome $f$ faults. \textbf{Interactive consistency} between $n$ processors can be achieve if and only if $n > 3f$ with $f$ faults.\par
\textbf{Oral Messages Algorithms}\label{oralMessagesAlgorithm} (not covered in this summary) achive interactive consistency.

\subsubsection{Authenticators}
The results seen rely on the assumptions of byzantine processors and the timing model.\par
\highlight{Authenticators} are metadata that ensure the \textbf{authenticity} and \textbf{integrity} of data (by using cryptography). They can be used to improve the results.

\subsection{Byzantine Reliable Broadcast: Asynchronous Case}
\subsubsection{Bracha's Reliable Broadcast}
\highlight{Bracha's Reliable Broadcast} \cite{BRACHA1987130} is an efficient reliable broadcast algorithm for \textbf{asynchronous} systems.\par
\textbf{Assumptions}:
\begin{itemize}
  \item{System consists of $n$ processes communicating via a \textit{reliable message system}}
  \item{The system requires $n \geq 3f + 1$ processes to tolerate $f$ byzantine faults}
\end{itemize}
\textbf{Objectives:} One sender $p$ wants to broadcast a value $v$. The algorithms satisfies the following properties:
\begin{itemize}
  \item{If $p$ is correct, then all correct processes agree on $v$}
  \item{If $p$ is faulty, then either all correct processes agree on the same value or none of them accepts any value from $p$}
\end{itemize}
Bracha's Reliable Broadcas has a message complexity of $O(n^2)$. The algoritm is not covered in this summary.

\section{Consensus and Variants}
In distributed systems, achieving \highlight{consensus} is crucial for coordinating and ensuring consistent states across multiple nodes.

\subsection{Definitions}
Each node $i$ proposes a value $v_i$.
\begin{itemize}
  \item \highlight{Termination}: Every correct process eventually decides some value.
  \item \highlight{Weak Validity}: If all processes are correct and propose the same value $v$, then no correct process decides a value different from $v$. If all processes are correct and some process decides $v$ then $v$ was previously proposed by some process
  \item \highlight{Strong Validity}: If all correct processes propose the same value $v$, then no correct process decides a value different from $v$. Otherwise, a correct process may only decide a value that was proposed by some correct process or special value
  \item \highlight{Integrity}: No process decides twice.
  \item \highlight{Agreement}: No two correct processes decide differently.
\end{itemize}

\subsection{Consensus in Synchronous Systems}
With consensus, state machine replication can be realized. To tolerate faults, we need two requirements:
\begin{itemize}
  \item{\highlight{Agreement}: Every nonfaulty replica (= state machine) receives every request}
  \item{\highlight{Order}: Every nonfaulty replica processes the requests it receives in the same relative order}
\end{itemize}

\subsection{Consensus in Asynchronous Systems}
\subsubsection{Impossibility of Deterministic Consensus}
Deterministic consensus is \textbf{impossible} in asynchronous systems with even \textbf{one faulty} (crash-fault) process \cite{impossibilityDistributedConsensus}.

\subsubsection{Asynchronous Consensus without Faults}
There are $N$ processes with unique IDs, at least a simple majority of which are \textbf{active}, the rest remain \textbf{inactive forever}. Active processes \textbf{never crash or behave arbitrarily}. Assumptions for the asynchronous communication:
\begin{itemize}
  \item{Sent messages are \textbf{delivered eventually}}
  \item{Received messages were \textbf{sent by an active process}}
  \item{Messages can be delayed or reordered}
\end{itemize}
The goal is to reach \highlight{consensus} between active processes: Each active process stars with an \textbf{initial value} and terminates with a \textbf{decision value} that was \textbf{proposed by some active process}.
\begin{itemize}
  \item{\highlight{Safety}: Active processes terminate}
  \item{\highlight{Liveness}: Terminating processes must agree on the decision value}
\end{itemize}
Problems:
\begin{itemize}
  \item{Finding other active processes}
  \item{Finding all active processes}
  \item{Finding agreement between active processes}
\end{itemize}

\subsubsection{Bracha's Consensus}
\textbf{Bracha's consensus protocol} is conducted in phases that are executed by all processes. The focus is on \textbf{binary input values}. There are up to $f$ byzanine nodes out of $n > 3f$ nodes. The protocol satisfies the following properties:
\begin{itemize}
  \item \highlight{Validity}: If all correct processes start with the same value $v$, then all correct processes decide on $v$.
  \item \highlight{Agreement}: All correct processes decide on the same value.
  \item \highlight{Probabilistic Termination}: The probability that a correct process is undecided after $r$ rounds approaches zero as $r$ approaches infinity.
\end{itemize}
Bracha's consensus protocol is not covered in this summary.

\subsection{Total Order Broadcast}
\highlight{Total order broadcast} (or \textbf{atomic broadcast}) ensures a total order of transmitted messages, maintaining:
\begin{itemize}
  \item \highlight{Validity}: If a correct process broadcasts a message $m$, then it eventually delivers $m$.
  \item \highlight{Agreement}: If a correct process delivers a message $m$, then all correct processes eventually deliver $m$.
  \item \highlight{Integrity}: For any message $m$, every correct process delivers $m$ at most once, and only if $m$ was previously broadcast.
  \item \highlight{Total order}: If correct processes $p$ and $q$ both deliver messages $m$ and $m'$, then $p$ delivers $m$ before $m'$ if and only if $q$ delivers $m$ before $m'$.
\end{itemize}

\subsection{Practical Byzantine Fault Tolerance (PBFT)}
The Oral Messaging Algorithm in inefficient in number of rounds and messages. The \highlight{Practical Byzantine Fault Tolerance (PBFT)} \cite{PBFT} algorithm is based on Bracha's Reliable Broadcast.\par
It provides \textbf{State machine replication}, one \textbf{deterministic} state machine is replicated across multiple processors (called \textbf{replicas} or \textbf{backups}). High-level overview:
\begin{enumerate}
  \item{Clients issue requests that should be executed by the state machine}
  \item{A request is issued to the current \textit{primary} (leader)}
  \item{The primary sends the request to all backups}
  \item{The backups process the request and send their reply to the client}
  \item{The client accepts the result when it gets at least $f+1$ replies with the same result}
\end{enumerate}
At most $f$ processors are faulty. The requests issued by the clients are executed \textbf{in the same order} on all replicas. Before executing a request, a \textbf{total order} is established.

\subsubsection{From Bracha's Reliable Broadcast to PBFT}
\begin{itemize}
  \item \textbf{Agreement Protocol}: PBFT executes \textbf{Bracha's Reliable Broadcast} for each client request
  \item \textbf{View Change}: PBFT uses \textbf{timer} and \textbf{view changes} to guarantee termination
  \item \textbf{Garbage Collection}: PBFT uses \textbf{checkpoints} to clear up storage
\end{itemize}

\subsubsection{PBFT System Model}
\begin{itemize}
  \item Partially (weakly) synchronous system: Delay $\Delta(t)$ doesn't grow faster than $t$ indefinitely
  \item Set of replicas $R = \{0, \dots, n-1\}$, $|R| = n$
  \item $n = 3f + 1$ with $f$ number of faults that must be tolarated without losing safety or liveness
  \item Crypto assumptions: Public key signatures and Message authentication codes
\end{itemize}

\subsubsection{PBFT Views}
A \textbf{view} is a period during operation which has one replica designated as the \textbf{primary} (leader).
\begin{itemize}
  \item The primary receives requests from clients, assigns them a unique sequence number and initiates the consensus protocol
  \item If the primary becomes unresponsive, another replica will initiate a \textbf{view change} to select a new primary
  \item The primary of a view is replica $p$ such that $p = v \mod |R|$ with $v$ being the view number
\end{itemize}
A \textbf{View change} is triggered by \textbf{timeouts}. The View Change protocol is not covered in this summary.

\subsubsection{PBFT Phases}
In view $v$ with primary $p = v \mod |R|$, every client request goes through three phases:
\begin{enumerate}
  \item \textbf{Pre-prepare}: On receiving a client request $r$, the primary assigns a sequence number $n$ and broadcasts a \textbf{pre-prepare} message $(r, n, v)$ to all replicas
  \item \textbf{Prepare}: On receiving a consistent and non-conflicting \textbf{pre-prepare} message with sequence number $h < n < H$ (sliding window of accepted sequence numbers), a backup broadcasts a \textbf{prepare} message $(r, n, v)$ to all replicas
  \item \textbf{Commit}: Once a replica has received $2f$ \textbf{prepare} messages from \textbf{different backups} that are consistent with the \textbf{pre-prepare}, it broadcasts a \textbf{commit} message $(r, n, v)$ to all replicas
\end{enumerate}
Once a replica received $2f + 1$ consistent \textbf{commit} messages (possibly including its own), it performs the requested operation and \textbf{replies} to the client.\par
The client accepts the result after it received $f + 1$ consistent \textbf{replies}.

\subsubsection{PBFT Garbage Collection: Checkpoints}
Messages related to a request have to be kept in a replica's log until it knows that the request has been executed by at least $f+1$ correct replicas.\par
\textbf{Checkpoints} are a collection of proofs that requests have been executed and the state has changed. The \textbf{checkpoint protocol} is executed periodically and represents the state that results from executing the requests covered by this checkpoint.

\subsubsection{PBFT Safety and Liveness}
\begin{itemize}
  \item \highlight{Safety}: The 3-phase structure ensures that all replicas execute the same operations in exactly the same order
  \item \highlight{Liveness}: View-change ensures liveness in case of a faulty primary
\end{itemize}

\subsection{DAG-Rider}
\textbf{DAG-Rider} \cite{dagRider} has been proposed as an asynchronous total order broadcase based on a \textbf{directed acyclic graph (DAG)} structure.
\begin{itemize}
  \item In each asynchronous round, each correct process \textbf{bundles client requests into a DAG-vertex} with at least $2f + 1$ edges to verticies of the preceding round it knows about before \textbf{reliably broadcasting} this new vertex to other processes
  \item When receiving a vertex, a correct process checks wheter it also knows its \textbf{causal history} and holds new vertices back until it does
  \item \textbf{Four rounds are grouped into a wave}. Once a wave is finished for a process, a vertex in its first round is designated as a \textbf{leader vertex} through a mechanism called \textbf{common coin}
  \item Through leader vertices, all vertices and contained requests in a wave are then \textbf{totally ordered}
\end{itemize}
DAG-Rider doesn't need view-changes, checkpoints or garbage collection and is described in 57 lines of pseudo code.

\section{Current Research}

\subsection{State Machine Replication}
\subsubsection{Recap: State Machine Replication}
\begin{itemize}
  \item Implements fault-tolerant service by replicating servers and coordinating client requests
  \item All replicas need to receive and process the same sequence of requests
  \item Replicas need to keep their states consistent
\end{itemize}

\subsubsection{State Machine Replication Issues}
\begin{itemize}
  \item Replication is expensive
  \item Scalability is difficult
\end{itemize}
Instead of Byzantine fault tolerance, we could make use of \textbf{Trusted Execution Environments (TEEs)} and only handle crash-fault.

\subsection{Trusted Execution Environments (TEEs)}
The objective of a \highlight{Trusted Execution Environment (TEE)} is to provide a secure and isolated environment for processing data.

\subsubsection{Properties of TEEs}
\begin{itemize}
  \item{\highlight{Confidential computation}
              \begin{itemize}
                \item Isolated process execution
                \item Main memory protection
                \item Persistent secured storage
              \end{itemize}}
  \item{\highlight{Attestation} of hard-, software and developer identity}
\end{itemize}
A TEE may \textbf{only fail by crashing}. Assumption: Byzantine attackers cannot break the TEEs.


\subsection{TEE-based Reliable Broadcast}
\subsubsection{Definition: Byzantine Broadcast Channel}
A sender $p_s \in P$, $n := |P|$ can call $\textit{broadcast}(c, m)$. Correct processes deliver tuples $(c, m)$ where $c \in \mathbb{N}$ and $m$ an arbitrary message, satisfying the following properties:

\begin{itemize}
  \item \textbf{RB-Agreement:} If a correct process delivers $(c, m)$, then every other correct process eventually delivers $(c, m)$.
  \item \textbf{RB-Integrity:} For each $c \in \mathbb{N}$, each correct process delivers $(c, m)$ at most once.
  \item \textbf{RB-Validity:} If a correct sender calls $\textit{broadcast}(c, m)$, then every other correct process eventually delivers $(c, m)$.
\end{itemize}

\subsubsection{TEE-based Reliable Broadcast: Setting}
\begin{itemize}
  \item \textbf{Byzantine faults}: $n > f$ processes, where at most $f$ processes may behave arbitrarily
  \item \textbf{Asynchrony}: No upper bound on computation and communication delays
  \item \textbf{Eventual delivery}: Each message sent by a correct process will eventually be delivered
  \item \textbf{Trusted Execution Environment}: The sender is equipped with a TEE that may only fail by crashing
\end{itemize}
The TEE-based Reliable Broadcast: Algorithm is not covered in this summary.


\subsection{TEE-Rider}

\subsubsection{TEE-Rider: Goal}
Implement asynchronous Byzantine fault tolerant Total Order Broadcast with $n \geq 2f + 1$ processes

\subsubsection{TEE-Rider: Setting}
\begin{itemize}
  \item \textbf{Asynchrony}: No upper bound on computation and communication delays
  \item \textbf{Eventual delivery}: Each message sent by a correct process will eventually be delivered
  \item \textbf{Authenticated Full Mesh Network}: Every process has an authenticated point-to-point link to every other process
  \item \textbf{Infinite stream of client requests}: Each correct process receives an infinite stream of client requests
  \item \textbf{Trusted Execution Environment}: The sender is equipped with a TEE that may only fail by crashing
  \item \textbf{Synchronous Setup Phase}: Before ``normal'' operations, building blocks are initialized in a phase that requires synchrous communication
\end{itemize}

\subsubsection{TEE-Rider in a Nutshell}

\begin{itemize}
  \item \textbf{Round-based}: Progress in asynchronous logical rounds
  \item \textbf{Leaderless protocol}: Every process has the exact same task
  \item \textbf{DAG-based}: Processes maintain a grow-only DAG that encodes the causal order of messages
\end{itemize}
The exact TEE-Rider protocol is not covered in this summary.

\newpage
\bibliographystyle{apalike}
\bibliography{\jobname}


\end{document}